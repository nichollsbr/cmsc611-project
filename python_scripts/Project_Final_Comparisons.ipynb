{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bnicholls/Documents/School/cmsc611-project/python_scripts\n",
      "/Users/bnicholls/Documents/School/cmsc611-project\n",
      "['BasicDataframeRunner-2018-12-09T07:27:23.1544340443Z', 'BasicDataframeRunner-2018-12-09T07:30:52.1544340652Z', 'BasicDataframeRunner-2018-12-09T07:12:34.1544339554Z', 'BasicDataframeRunner-2018-12-09T07:32:57.1544340777Z', 'BasicDataframeRunner-2018-12-09T07:20:38.1544340038Z', 'BasicDataframeRunner-2018-12-09T07:35:01.1544340901Z', 'BasicDataframeRunner-2018-12-09T07:17:42.1544339862Z', 'BasicDataframeRunner-2018-12-09T07:15:07.1544339707Z', 'BasicDataframeRunner-2018-12-09T07:09:59.1544339399Z', 'BasicDataframeRunner-2018-12-09T07:33:59.1544340839Z', 'BasicDataframeRunner-2018-12-09T07:25:05.1544340305Z', 'BasicDataframeRunner-2018-12-09T07:07:23.1544339243Z', 'BasicDataframeRunner-2018-12-09T07:23:36.1544340216Z', 'BasicDataframeRunner-2018-12-09T07:28:33.1544340513Z', 'BasicDataframeRunner-2018-12-09T07:22:07.1544340127Z', 'BasicDataframeRunner-2018-12-09T07:29:42.1544340582Z']\n"
     ]
    }
   ],
   "source": [
    "# Script to get JSON data from \n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "cwd = os.getcwd()\n",
    "if cwd.startswith(\"C\"):\n",
    "    cwd = \"C:\\\\Users\\\\maria\\\\Documents\\\\Grad School\\\\Fall2018\\\\CMSC611\\\\Projects\\\\all-20181213T021317Z-001\\\\all\\\\\"\n",
    "stats_dir = \"spark-stats\"\n",
    "metrics_dir = \"metrics\"\n",
    "base_dir = os.path.dirname(cwd)\n",
    "\n",
    "spark_stats_dir=\"\"\n",
    "spark_metrics_dir=\"\"\n",
    "if(cwd.startswith(\"C\")): #On a Windows\n",
    "    spark_stats_dir = base_dir + \"\\\\\" + stats_dir\n",
    "    spark_metrics_dir = base_dir + \"\\\\\" + metrics_dir\n",
    "else:\n",
    "    spark_stats_dir = base_dir + \"/\" + stats_dir\n",
    "    spark_metrics_dir = base_dir + \"/\" + metrics_dir\n",
    "\n",
    "metric_output_mapping = {\n",
    "    \"basic-dataframe-run-output\": \"BasicDataframe\",\n",
    "    \"basic-dataset-run-output\": \"BasicDataset\",\n",
    "    \"basic-rdd-run-output\": \"BasicRDD\",\n",
    "    \"cache-dataframe-run-output\": \"CacheDataframe\",\n",
    "    \"cache-dataset-run-output\": \"CacheDataset\",\n",
    "    \"cache-rdd-run-output\": \"CacheRDD\",\n",
    "    \"kmeans-dataframe-run-output\": \"KMeansDataframe\",\n",
    "    \"kmeans-dataset-run-output\": \"KMeansDataset\",\n",
    "    \"map-partitions-rdd-run-output\": \"MapPartitionsRDD\",\n",
    "    \"map-rdd-run-output\": \"MapRDD\",\n",
    "    \"partition-dataframe-run-output\": \"PartitionDataframe\",\n",
    "    \"parititon-dataset-run-output\": \"PartitionDataset\",\n",
    "    \"partition-rdd-run-output\": \"PartitionRDD\"\n",
    "}\n",
    "\n",
    "metric_output_mapping_inv = {v: k for k, v in metric_output_mapping.items()}\n",
    "\n",
    "def get_spark_stats_file(fileName):\n",
    "    if(cwd.startswith(\"C\")):\n",
    "        return spark_stats_dir + \"\\\\\" + fileName\n",
    "    else:\n",
    "        return spark_stats_dir + \"/\" + fileName\n",
    "\n",
    "def get_metrics_file(fileName):\n",
    "    if(cwd.startswith(\"C\")):\n",
    "        return spark_metrics_dir + \"\\\\\" + fileName\n",
    "    else:\n",
    "        return spark_metrics_dir + \"/\" + fileName\n",
    "\n",
    "def get_associated_filenames(run_output_name):\n",
    "    if(cwd.startswith(\"C\")): #On a Windows\n",
    "        valid_files = list(pd.read_csv(spark_metrics_dir + \"\\\\\" + run_output_name)[\"appName\"])\n",
    "        return [spark_stats_dir + \"\\\\\" + a_file for a_file in os.listdir(spark_stats_dir) if a_file in valid_files]\n",
    "    else:\n",
    "        valid_files = list(pd.read_csv(spark_metrics_dir + \"/\" + run_output_name)[\"appName\"])\n",
    "        return [a_file for a_file in os.listdir(spark_stats_dir) if a_file in valid_files]\n",
    "\n",
    "def get_run_params(appName):\n",
    "    for beginningOutput in metric_output_mapping_inv:\n",
    "        if appName.startswith(beginningOutput):\n",
    "            metrics_df = pd.read_csv(get_metrics_file(metric_output_mapping_inv[beginningOutput]))\n",
    "            return metrics_df[metrics_df[\"appName\"] == appName]\n",
    "    \n",
    "print(cwd)\n",
    "print(base_dir)\n",
    "print(get_associated_filenames(\"basic-dataframe-run-output\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BasicDataframe': 'basic-dataframe-run-output',\n",
       " 'BasicDataset': 'basic-dataset-run-output',\n",
       " 'BasicRDD': 'basic-rdd-run-output',\n",
       " 'CacheDataframe': 'cache-dataframe-run-output',\n",
       " 'CacheDataset': 'cache-dataset-run-output',\n",
       " 'CacheRDD': 'cache-rdd-run-output',\n",
       " 'KMeansDataframe': 'kmeans-dataframe-run-output',\n",
       " 'KMeansDataset': 'kmeans-dataset-run-output',\n",
       " 'MapPartitionsRDD': 'map-partitions-rdd-run-output',\n",
       " 'MapRDD': 'map-rdd-run-output',\n",
       " 'PartitionDataframe': 'partition-dataframe-run-output',\n",
       " 'PartitionDataset': 'parititon-dataset-run-output',\n",
       " 'PartitionRDD': 'partition-rdd-run-output'}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_output_mapping_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-44-5e6f5cc930c0>, line 65)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-44-5e6f5cc930c0>\"\u001b[0;36m, line \u001b[0;32m65\u001b[0m\n\u001b[0;31m    for: # TODO, add a line for each metric instead of bar\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Graph to compare min and max finish time amongst all of the metrics\n",
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import json\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# Extracts statistics from the data object which is an array of job dictionaries\n",
    "# processes stat if necessary\n",
    "def extract_stat(data_obj, stat_x, stat_y):\n",
    "    stats_x = []\n",
    "    stats_y = []\n",
    "    for job in data_obj:\n",
    "        stat_value_x = None\n",
    "        stat_value_y = None\n",
    "        # Account for stats in which two values need to be subtracted\n",
    "        if isinstance(stat_x, tuple):\n",
    "            stat_value_x = abs(job[stat_x[0]] - job[stat_x[1]])\n",
    "        if isinstance(stat_y, tuple):\n",
    "            stat_value_y = abs(job[stat_y[0]] - job[stat_y[1]])\n",
    "        if not stat_value_x:\n",
    "            stat_value_x = job[stat_x]\n",
    "        if not stat_value_y:\n",
    "            stat_value_y = job[stat_y]\n",
    "            \n",
    "        stats_x.append(stat_value_x)\n",
    "        stats_y.append(stat_value_y)\n",
    "    return (max(stats_x), max(stats_y))\n",
    "\n",
    "# generates a graph that compares the given metrics with the 2 statistics\n",
    "# \n",
    "# metrics - The list of metrics\n",
    "# stat_x - The name of the stat as shown in the json. If the stat contains a tuple of 2, the difference\n",
    "# of the first and second in the tuple will be used.\n",
    "# stat_y - The name of the other stat as shown in the json\n",
    "def generate_comparison(metrics, stat_x, stat_y):\n",
    "\n",
    "    n_groups=16\n",
    "    fig, ax = plt.subplots(figsize=(15,10))\n",
    "\n",
    "    index = np.arange(n_groups)\n",
    "    bar_width = 0.2\n",
    "\n",
    "    opacity = 0.4\n",
    "    error_config = {'ecolor': '0.3'}\n",
    "\n",
    "    metric_stats = {}\n",
    "    for metric in metrics:\n",
    "        metric_stats[metric] = {stat_x: None, stat_y:None}\n",
    "        data_files = get_associated_files(metric)\n",
    "        stat_values_x = []\n",
    "        stat_values_y = []\n",
    "        for data_file in data_files:\n",
    "            # Compile the data file path\n",
    "            data_file_path = os.path.join(cwd, stats_dir)\n",
    "            fp = open(pathed)\n",
    "            data_obj = json.load(fp)\n",
    "            stat_value_x, stat_value_y = extract_stat(data_obj, stat_x, stat_y)\n",
    "            stat_values_x.append(stat_value_x)\n",
    "            stat_values_y.append(stat_value_y)\n",
    "        metric_stats[metric][stat_x] = max(stat_values_x)\n",
    "        metric_stats[metric][stat_y] = max(stat_values_y)\n",
    "        \n",
    "    for: # TODO, add a line for each metric instead of bar\n",
    "        rects1 = ax.bar(x, [math.log(i,10) for i in y1], bar_width,\n",
    "                        alpha=opacity,\n",
    "                        error_kw=error_config,\n",
    "                        label='Dataframe')\n",
    "\n",
    "    ax.set_xlabel('Job Number (Determines Memory Setting)')\n",
    "    ax.set_ylabel('Peak Memory (Log Base 10)')\n",
    "    ax.set_title('Peak Execution Memory for Each Memory Setting')\n",
    "    ax.set_xticks(1 + index + bar_width)\n",
    "    ax.set_xticklabels(x)\n",
    "    ax.legend()\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bytesRead',\n",
       " 'bytesWritten',\n",
       " 'diskBytesSpilled',\n",
       " 'duration',\n",
       " 'executorCpuTime',\n",
       " 'executorDeserializeCpuTime',\n",
       " 'executorDeserializeTime',\n",
       " 'executorId',\n",
       " 'executorRunTime',\n",
       " 'finishTime',\n",
       " 'gettingResultTime',\n",
       " 'host',\n",
       " 'index',\n",
       " 'jobGroup',\n",
       " 'jobId',\n",
       " 'jvmGCTime',\n",
       " 'launchTime',\n",
       " 'memoryBytesSpilled',\n",
       " 'numUpdatedBlockStatuses',\n",
       " 'peakExecutionMemory',\n",
       " 'recordsRead',\n",
       " 'recordsWritten',\n",
       " 'resultSerializationTime',\n",
       " 'resultSize',\n",
       " 'schedulerDelay',\n",
       " 'shuffleBytesWritten',\n",
       " 'shuffleFetchWaitTime',\n",
       " 'shuffleLocalBlocksFetched',\n",
       " 'shuffleRecordsWritten',\n",
       " 'shuffleRemoteBlocksFetched',\n",
       " 'shuffleTotalBlocksFetched',\n",
       " 'shuffleTotalBytesRead',\n",
       " 'shuffleWriteTime',\n",
       " 'speculative',\n",
       " 'stageId',\n",
       " 'successful',\n",
       " 'taskLocality']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_partitions_files = get_associated_filenames(\"map-partitions-rdd-run-output\")\n",
    "map_files = get_associated_filenames(\"map-rdd-run-output\")\n",
    "sample = pd.read_json(get_spark_stats_file(map_partitions_files[0]))\n",
    "list(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12834\n",
       "0    12834\n",
       "Name: stageId, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"stageId\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_execution_time(df):\n",
    "    start_time = datetime.datetime.fromtimestamp(min(df[\"launchTime\"])/1000.0)\n",
    "    end_time = datetime.datetime.fromtimestamp(max(df[\"finishTime\"])/1000.0)\n",
    "    time_range = end_time - start_time\n",
    "    return (start_time, end_time, time_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = get_full_execution_time(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.datetime(2018, 12, 9, 0, 44, 13, 692000),\n",
       " datetime.datetime(2018, 12, 9, 0, 45, 16, 578000),\n",
       " datetime.timedelta(0, 62, 886000))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appName</th>\n",
       "      <th>threadCount</th>\n",
       "      <th>executorMem</th>\n",
       "      <th>overheadMem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MapPartitionsRDDRunner-2018-12-09T05:42:18.154...</td>\n",
       "      <td>4</td>\n",
       "      <td>1024m</td>\n",
       "      <td>384m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              appName  threadCount  \\\n",
       "13  MapPartitionsRDDRunner-2018-12-09T05:42:18.154...            4   \n",
       "\n",
       "   executorMem overheadMem  \n",
       "13       1024m        384m  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_run_params(map_partitions_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
